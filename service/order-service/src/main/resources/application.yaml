server:
  port: 9006

spring:
  application:
    name: order-service
  datasource:
    druid:
      # 初始化时建立物理连接的个数
      initial-size: 5
      # 最大连接池数量
      max-active: 20
      # 最小连接池数量
      min-idle: 5
      # 获取连接时最大的等待时间, 单位毫秒
      max-wait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位毫秒
      time-between-eviction-runs-millis: 60000
      # 连接保持空闲而不被驱逐的最小时间, 单位毫秒
      min-evictable-idle-time-millis: 30000
      max-evictable-idle-time-millis: 60000
      # 配置监控统计拦截的 filters, 去掉后监控界面 SQL 无法统计
      filters: stat,wall
      # 通过 connectProperties 属性打开 mergeSql 功能，慢 SQL 记录
      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500
      # 合并多个 DruidDataSource 的监控数据
      use-global-data-source-stat: true
      stat-view-servlet:
        enabled: true
      master:
        url: jdbc:mysql://localhost:3306/double?serverTimezone=GMT%2B8
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
        type: com.alibaba.druid.pool.DruidDataSource
      slave:
        url: jdbc:oracle:thin:@localhost:1521:XE
        platform: oracle
        username: clp
        password: clp
        type: com.alibaba.druid.pool.DruidDataSource
        driver-class-name: oracle.jdbc.OracleDriver

  jersey:
    application-path: ${spring.application.name}
    type: servlet
    servlet:
      load-on-startup: 1
    init: { jersey.config.beanValidation.enableOutputValidationErrorEntity.server: true }

  kafka:
    bootstrap-servers: localhost:19092
    producer:
      retries: 0
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer